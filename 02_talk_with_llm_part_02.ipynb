{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "004c40de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4156cc7d",
   "metadata": {},
   "source": [
    "### Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c4a43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llmModel = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67fa982",
   "metadata": {},
   "source": [
    "### Chat-Completion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169a9663",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel = ChatOpenAI(model = \"gpt-3.5-turbo-0125\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bf857d",
   "metadata": {},
   "source": [
    "### Prompts and PromptTemplates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cde7105e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "One of the most well-known and controversial families in American history, the Kennedys have a long history of political power and personal tragedies. However, one lesser-known aspect of the Kennedy family is their connection to the world of competitive sailing.\n",
      "\n",
      "In 1932, Joseph P. Kennedy Sr., the patriarch of the Kennedy family, purchased a 50-foot sailboat named Victura for his children to learn how to sail. The boat quickly became a favorite pastime for the Kennedy children, particularly John F. Kennedy, who became an accomplished sailor and even skippered Victura in several races.\n",
      "\n",
      "But it wasn't until 1962 that the Kennedy family's love for sailing took a strange turn. In the midst of the Cold War, tensions were high between the United States and the Soviet Union. In an effort to ease the tension, President Kennedy proposed a series of friendly sporting competitions between the two countries, including a sailing race.\n",
      "\n",
      "The Soviets, eager to prove their superiority, accepted the challenge and sent their best sailors to compete against the Kennedys on Victura. The race was highly publicized and thousands of spectators gathered to watch the two teams battle it out on the open water.\n",
      "\n",
      "In a stunning turn of events, the Kennedy family emerged victorious, beating the Soviet\n"
     ]
    }
   ],
   "source": [
    "# This is for completion Model\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} story about {topic}\"\n",
    ")\n",
    "\n",
    "llmModelPrompt = prompt_template.format(\n",
    "    adjective = \"curious\",\n",
    "    topic = \"The Kennedy family\"\n",
    ")\n",
    "\n",
    "res = llmModel.invoke(llmModelPrompt)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517498f6",
   "metadata": {},
   "source": [
    "### Prompt Template for ChatCompletionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509f9a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Joseph P. Kennedy, Sr., the patriarch of the Kennedy family, had a total of 34 grandchildren.' response_metadata={'token_usage': {'completion_tokens': 22, 'prompt_tokens': 55, 'total_tokens': 77, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-d954d213-6007-466e-bebb-cff3dce7a3af-0' usage_metadata={'input_tokens': 55, 'output_tokens': 22, 'total_tokens': 77}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are an {profession} expert on {topic}\"),\n",
    "        (\"human\",\"Hello, Mr. {profession}, can you please answer a question?\"),\n",
    "        (\"ai\",\"Sure!\"),\n",
    "        (\"human\",\"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(\n",
    "    profession = \"Historian\",\n",
    "    topic = \"The Kennedy Family\",\n",
    "    user_input = \"How many grand children had Joseph P. Kennedy?\"\n",
    ")\n",
    "\n",
    "response = chatModel.invoke(messages)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a07ca7",
   "metadata": {},
   "source": [
    "# Few Shot Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f8b72fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "examples=[{'input': 'hi!', 'output': 'hola!'}, {'input': 'bye!', 'output': 'adios!'}] example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], template='{output}'))])\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"hi!\",\"output\":\"hola!\"},\n",
    "    {\"input\":\"bye!\",\"output\":\"adios!\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"{input}\"),\n",
    "        (\"ai\",\"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an English-spanish translator\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(few_shot_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60b2deb",
   "metadata": {},
   "source": [
    "### Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "900da7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿Cómo estás?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate\n",
    "\n",
    "examples = [\n",
    "    {\"input\":\"hi!\",\"output\":\"hola!\"},\n",
    "    {\"input\":\"bye!\",\"output\":\"adios!\"}\n",
    "]\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\",\"{input}\"),\n",
    "        (\"ai\",\"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    examples = examples\n",
    ")\n",
    "\n",
    "final_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\"You are an English-spanish translator\"),\n",
    "    few_shot_prompt,\n",
    "    (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = final_prompt | chatModel \n",
    "\n",
    "res = chain.invoke({\"input\": \"How are you?\"})\n",
    "print(res.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b422e",
   "metadata": {},
   "source": [
    "### Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2bf52e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'As of 2021, the population of India is approximately 1.38 billion.'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers.json import SimpleJsonOutputParser\n",
    "\n",
    "json_prompt = PromptTemplate.from_template(\n",
    "    \"Return a JSON Object with an 'answer' key that answers the following question: {question}\"\n",
    ")\n",
    "\n",
    "json_parser = SimpleJsonOutputParser()\n",
    "\n",
    "json_chain = json_prompt | llmModel | json_parser\n",
    "\n",
    "json_chain.invoke({\"question\": \"What is the population of India in present?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a7f7b1",
   "metadata": {},
   "source": [
    "### Optionally, you can use pydantic to define a custom output format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3797db08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel,Field \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7112dae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"Question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d3cc59c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'setup': \"Why couldn't the bicycle stand up by itself?\",\n",
       " 'punchline': 'It was two tired!'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parser referring the pydantic object\n",
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"Answer the user query. \\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "chain = prompt | chatModel | parser \n",
    "\n",
    "chain.invoke({\"query\": \"Tell me a joke.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fa53cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmapp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
